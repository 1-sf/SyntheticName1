{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "from mistral_client import run_mistral\n",
    "from ner_post_processing import parse_entities_promptner, get_token_labels\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"DFKI-SLT/cross_ner\", \"politics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-academicjournal': 1,\n",
       " 'I-academicjournal': 2,\n",
       " 'B-album': 3,\n",
       " 'I-album': 4,\n",
       " 'B-algorithm': 5,\n",
       " 'I-algorithm': 6,\n",
       " 'B-astronomicalobject': 7,\n",
       " 'I-astronomicalobject': 8,\n",
       " 'B-award': 9,\n",
       " 'I-award': 10,\n",
       " 'B-band': 11,\n",
       " 'I-band': 12,\n",
       " 'B-book': 13,\n",
       " 'I-book': 14,\n",
       " 'B-chemicalcompound': 15,\n",
       " 'I-chemicalcompound': 16,\n",
       " 'B-chemicalelement': 17,\n",
       " 'I-chemicalelement': 18,\n",
       " 'B-conference': 19,\n",
       " 'I-conference': 20,\n",
       " 'B-country': 21,\n",
       " 'I-country': 22,\n",
       " 'B-discipline': 23,\n",
       " 'I-discipline': 24,\n",
       " 'B-election': 25,\n",
       " 'I-election': 26,\n",
       " 'B-enzyme': 27,\n",
       " 'I-enzyme': 28,\n",
       " 'B-event': 29,\n",
       " 'I-event': 30,\n",
       " 'B-field': 31,\n",
       " 'I-field': 32,\n",
       " 'B-literarygenre': 33,\n",
       " 'I-literarygenre': 34,\n",
       " 'B-location': 35,\n",
       " 'I-location': 36,\n",
       " 'B-magazine': 37,\n",
       " 'I-magazine': 38,\n",
       " 'B-metrics': 39,\n",
       " 'I-metrics': 40,\n",
       " 'B-misc': 41,\n",
       " 'I-misc': 42,\n",
       " 'B-musicalartist': 43,\n",
       " 'I-musicalartist': 44,\n",
       " 'B-musicalinstrument': 45,\n",
       " 'I-musicalinstrument': 46,\n",
       " 'B-musicgenre': 47,\n",
       " 'I-musicgenre': 48,\n",
       " 'B-organisation': 49,\n",
       " 'I-organisation': 50,\n",
       " 'B-person': 51,\n",
       " 'I-person': 52,\n",
       " 'B-poem': 53,\n",
       " 'I-poem': 54,\n",
       " 'B-politicalparty': 55,\n",
       " 'I-politicalparty': 56,\n",
       " 'B-politician': 57,\n",
       " 'I-politician': 58,\n",
       " 'B-product': 59,\n",
       " 'I-product': 60,\n",
       " 'B-programlang': 61,\n",
       " 'I-programlang': 62,\n",
       " 'B-protein': 63,\n",
       " 'I-protein': 64,\n",
       " 'B-researcher': 65,\n",
       " 'I-researcher': 66,\n",
       " 'B-scientist': 67,\n",
       " 'I-scientist': 68,\n",
       " 'B-song': 69,\n",
       " 'I-song': 70,\n",
       " 'B-task': 71,\n",
       " 'I-task': 72,\n",
       " 'B-theory': 73,\n",
       " 'I-theory': 74,\n",
       " 'B-university': 75,\n",
       " 'I-university': 76,\n",
       " 'B-writer': 77,\n",
       " 'I-writer': 78}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_labels = dataset[\"validation\"].features[\"ner_tags\"].feature.names\n",
    "index2label = {i: label for i, label in enumerate(class_labels)}\n",
    "label2index = {v: k for k, v in index2label.items()}\n",
    "\n",
    "label2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 541\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 651\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  You are an expert linguist. Your task \n",
    " \n",
    "prompt = lambda text: f\"\"\"\n",
    "Dfn: An entity is a person (person), organisation (organisation), politician (politician), political party (politicalparty), event (event), election (election), \n",
    "country (country), location (location) or other political entity (misc). Dates, times, abstract concepts, adjectives, and verbs are not entities.\n",
    "\n",
    "Example 1: Sitting as a Liberal Party of Canada Member of Parliament (MP) for Niagara Falls, she joined the Canadian Cabinet after the Liberals defeated the \n",
    "Progressive Conservative Party of Canada government of John Diefenbaker in the 1963 Canadian federal election.\n",
    "\n",
    "Answer:\n",
    "1. Liberal Party of Canada | True | as it is a political party (politicalparty)\n",
    "2. Parliament | True | as it is an organisation (organisation)\n",
    "3. Niagara Falls | True | as it is a location (location)\n",
    "4. Canadian Cabinet | True | as it is a political entity (misc)\n",
    "5. Liberals | True | as it is a political group by not the party name (misc)\n",
    "6. Progressive Conservative Party of Canada | True | as it is a political party (politicalparty)\n",
    "7. government | False | as it is not actually an entity in this sentence\n",
    "8. John Diefenbaker | True | as it is a politician (politician)\n",
    "9. 1963 Canadian federal election | True | as it is an election (election)\n",
    "\n",
    "Example 2: The MRE took part to the consolidation of The Olive Tree as a joint electoral list both for the\n",
    "2004 European Parliament election and the 2006 Italian general election, along with the Democrats of the Left\n",
    "and Democracy is Freedom - The Daisy.\n",
    "\n",
    "Answer:\n",
    "1. MRE | True | as it is a political party (politicalparty)\n",
    "2. consolidation | False | as it is an action\n",
    "3. The Olive Tree | True | as it is a group or organisation (organisation)\n",
    "4. 2004 European Parliament election | True | as it is an election (election)\n",
    "5. 2006 Italian general election | True | as it is an election (election)\n",
    "6. Democrats of the Left | True | as it is a political party (politicalparty)\n",
    "7. Democracy is Freedom - The Daisy | True | as it is an political party (politicalparty)\n",
    "\n",
    "Q. Given the paragraph below, identify a list of possible entities and for each entry explain why it either is or is not an entity.\n",
    "\n",
    "Paragraph: {text}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/541 [00:21<1:09:20,  7.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'B-'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4/541 [00:26<1:00:01,  6.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'B-'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5/541 [00:33<59:03,  6.61s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'B-'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 8/541 [00:49<50:11,  5.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'B-persons'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 9/541 [00:53<45:46,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'B-'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 11/541 [01:03<44:11,  5.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'B-'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 14/541 [01:14<36:32,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'B-'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 15/541 [01:21<42:38,  4.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'B-'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 23/541 [02:06<53:54,  6.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'B-'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 25/541 [02:15<46:28,  5.40s/it]"
     ]
    }
   ],
   "source": [
    "scored = defaultdict(list)\n",
    "\n",
    "for idx, example in enumerate(tqdm(dataset[\"validation\"])):\n",
    "    if (idx + 1) % 100 == 0:\n",
    "        df_scored = pd.DataFrame(scored)\n",
    "        df_scored.to_csv(\"../data/scored/validation.csv\", index=False)\n",
    "    \n",
    "    try:\n",
    "        text = \" \".join(example[\"tokens\"])\n",
    "        prompt_input = prompt(text)\n",
    "        output = run_mistral(prompt_input)\n",
    "        ner_tags = get_token_labels(text, parse_entities_promptner(output), label2index)\n",
    "\n",
    "        scored[\"tokens\"].append(example[\"tokens\"])\n",
    "        scored[\"prompt\"].append(prompt_input)\n",
    "        scored[\"output\"].append(output)\n",
    "        scored[\"ner_tags\"].append(ner_tags)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "df_scored = pd.DataFrame(scored)\n",
    "df_scored.to_csv(\"../data/scored/validation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored = defaultdict(list)\n",
    "\n",
    "for idx, example in enumerate(tqdm(dataset[\"test\"])):\n",
    "    if (idx + 1) % 100 == 0:\n",
    "        df_scored = pd.DataFrame(scored)\n",
    "        df_scored.to_csv(\"../data/scored/test.csv\", index=False)\n",
    "    \n",
    "    try:\n",
    "        text = \" \".join(example[\"tokens\"])\n",
    "        prompt_input = prompt(text)\n",
    "        output = run_mistral(prompt_input)\n",
    "        ner_tags = get_token_labels(text, parse_entities_promptner(output), label2index)\n",
    "\n",
    "        scored[\"tokens\"].append(example[\"tokens\"])\n",
    "        scored[\"prompt\"].append(prompt_input)\n",
    "        scored[\"output\"].append(output)\n",
    "        scored[\"ner_tags\"].append(ner_tags)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "df_scored = pd.DataFrame(scored)\n",
    "df_scored.to_csv(\"../data/scored/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 6.34k/6.34k [00:00<00:00, 6.79MB/s]\n"
     ]
    }
   ],
   "source": [
    "# import evaluate\n",
    "\n",
    "# metric = evaluate.load(\"seqeval\")\n",
    "# metric.compute(predictions=[predictions], references=[labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mistral-ai-hackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
