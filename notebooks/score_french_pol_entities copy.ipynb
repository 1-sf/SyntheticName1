{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "from mistral_client import run_mistral\n",
    "from ner_post_processing import parse_entities_promptner, get_token_labels\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-academicjournal': 1,\n",
       " 'I-academicjournal': 2,\n",
       " 'B-album': 3,\n",
       " 'I-album': 4,\n",
       " 'B-algorithm': 5,\n",
       " 'I-algorithm': 6,\n",
       " 'B-astronomicalobject': 7,\n",
       " 'I-astronomicalobject': 8,\n",
       " 'B-award': 9,\n",
       " 'I-award': 10,\n",
       " 'B-band': 11,\n",
       " 'I-band': 12,\n",
       " 'B-book': 13,\n",
       " 'I-book': 14,\n",
       " 'B-chemicalcompound': 15,\n",
       " 'I-chemicalcompound': 16,\n",
       " 'B-chemicalelement': 17,\n",
       " 'I-chemicalelement': 18,\n",
       " 'B-conference': 19,\n",
       " 'I-conference': 20,\n",
       " 'B-country': 21,\n",
       " 'I-country': 22,\n",
       " 'B-discipline': 23,\n",
       " 'I-discipline': 24,\n",
       " 'B-election': 25,\n",
       " 'I-election': 26,\n",
       " 'B-enzyme': 27,\n",
       " 'I-enzyme': 28,\n",
       " 'B-event': 29,\n",
       " 'I-event': 30,\n",
       " 'B-field': 31,\n",
       " 'I-field': 32,\n",
       " 'B-literarygenre': 33,\n",
       " 'I-literarygenre': 34,\n",
       " 'B-location': 35,\n",
       " 'I-location': 36,\n",
       " 'B-magazine': 37,\n",
       " 'I-magazine': 38,\n",
       " 'B-metrics': 39,\n",
       " 'I-metrics': 40,\n",
       " 'B-misc': 41,\n",
       " 'I-misc': 42,\n",
       " 'B-musicalartist': 43,\n",
       " 'I-musicalartist': 44,\n",
       " 'B-musicalinstrument': 45,\n",
       " 'I-musicalinstrument': 46,\n",
       " 'B-musicgenre': 47,\n",
       " 'I-musicgenre': 48,\n",
       " 'B-organisation': 49,\n",
       " 'I-organisation': 50,\n",
       " 'B-person': 51,\n",
       " 'I-person': 52,\n",
       " 'B-poem': 53,\n",
       " 'I-poem': 54,\n",
       " 'B-politicalparty': 55,\n",
       " 'I-politicalparty': 56,\n",
       " 'B-politician': 57,\n",
       " 'I-politician': 58,\n",
       " 'B-product': 59,\n",
       " 'I-product': 60,\n",
       " 'B-programlang': 61,\n",
       " 'I-programlang': 62,\n",
       " 'B-protein': 63,\n",
       " 'I-protein': 64,\n",
       " 'B-researcher': 65,\n",
       " 'I-researcher': 66,\n",
       " 'B-scientist': 67,\n",
       " 'I-scientist': 68,\n",
       " 'B-song': 69,\n",
       " 'I-song': 70,\n",
       " 'B-task': 71,\n",
       " 'I-task': 72,\n",
       " 'B-theory': 73,\n",
       " 'I-theory': 74,\n",
       " 'B-university': 75,\n",
       " 'I-university': 76,\n",
       " 'B-writer': 77,\n",
       " 'I-writer': 78,\n",
       " 'B-frenchpolitician': 79,\n",
       " 'I-frenchpolitician': 80,\n",
       " 'B-frenchpoliticalparty': 81,\n",
       " 'I-frenchpoliticalparty': 82}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"DFKI-SLT/cross_ner\", \"politics\")\n",
    "\n",
    "class_labels = dataset[\"validation\"].features[\"ner_tags\"].feature.names + [\"B-frenchpolitician\", \"I-frenchpolitician\", \"B-frenchpoliticalparty\", \"I-frenchpoliticalparty\"]\n",
    "index2label = {i: label for i, label in enumerate(class_labels)}\n",
    "label2index = {v: k for k, v in index2label.items()}\n",
    "\n",
    "label2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_french = lambda text: f\"\"\"\n",
    "Dfn: An entity is a person (person), organisation (organisation), french politician (politician), french political party (politicalparty), event (event), election (election), \n",
    "country (country), location (location) or other political entity (misc). Dates, times, abstract concepts, adjectives, and verbs are not entities.\n",
    "\n",
    "Example 1: In the 2014 European Parliament election in France , the National Front won the elections with 24.85 % of the vote , a swing of 18.55 % , winning 24 seats , up from 3 previously .\n",
    "\n",
    "Answer:\n",
    "1. 2014 European Parliament election | True | as it is an election (election)\n",
    "2. France | True | as it is a country (country)\n",
    "3. National Front | True | as it is a political party (frenchpoliticalparty)\n",
    "\n",
    "Example 2: The FN received 33.9 % of the votes in the 2017 French presidential election , making it the largest Eurosceptic party in France .\n",
    "\n",
    "Answer:\n",
    "1. FN | True | as it is a political party (frenchpoliticalparty)\n",
    "2. 2017 French presidential election | True | as it is an election (election)\n",
    "3. Eurosceptic party | True | as it is a political party (frenchpoliticalparty)\n",
    "4. France | True | as it is a country (country)\n",
    "\n",
    "Example 3: The 2017 French presidential election caused a radical shift in French politics , as the prevailing parties of The Republicans and Socialists failed to make it to the second round of voting , with far-right Marine Le Pen and political newcomer Emmanuel Macron instead facing each other .\n",
    "\n",
    "Answer:\n",
    "1. 2017 French presidential election | True | as it is an election (election)\n",
    "2. French politics | False | as it is an abstract concept, not a specific entity\n",
    "3. The Republicans | True | as it is a political party (frenchpoliticalparty)\n",
    "4. Socialists | True | as it is a political party (frenchpoliticalparty)\n",
    "5. far-right | False | as it is an adjective describing a political orientation, not a specific entity\n",
    "6. Marine Le Pen | True | as she is a French politician (frenchpolitician)\n",
    "7. Emmanuel Macron | True | as he is a French politician (frenchpolitician)\n",
    "8. political newcomer | False | as it is an abstract concept, not a specific entity\n",
    "\n",
    "Q. Given the paragraph below, identify a list of possible entities and for each entry explain why it either is or is not an entity.\n",
    "\n",
    "Paragraph: {text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [21:26<00:00,  6.43s/it]\n"
     ]
    }
   ],
   "source": [
    "scored = defaultdict(list)\n",
    "\n",
    "for idx, example in enumerate(tqdm(dataset[\"train\"])):\n",
    "    if (idx + 1) % 100 == 0:\n",
    "        df_scored = pd.DataFrame(scored)\n",
    "        df_scored.to_csv(\"../data/scored/train_french.csv\", index=False)\n",
    "    \n",
    "    try:\n",
    "        text = \" \".join(example[\"tokens\"])\n",
    "        prompt_input = prompt_french(text)\n",
    "        output = run_mistral(prompt_input)\n",
    "        ner_tags = get_token_labels(text, parse_entities_promptner(output), label2index)\n",
    "\n",
    "        scored[\"id\"].append(example[\"id\"])\n",
    "        scored[\"tokens\"].append(example[\"tokens\"])\n",
    "        scored[\"prompt\"].append(prompt_input)\n",
    "        scored[\"output\"].append(output)\n",
    "        scored[\"ner_tags\"].append(ner_tags)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "df_scored = pd.DataFrame(scored)\n",
    "df_scored.to_csv(\"../data/scored/train_french.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mistral-ai-hackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
